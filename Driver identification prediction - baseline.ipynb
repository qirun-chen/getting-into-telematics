{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c77821",
   "metadata": {},
   "source": [
    "# Driver behavior mining\n",
    "\n",
    "Driver behavior mining can be an interesting topic in telemetics area. If we can learn the subtle patterns from risky drivers, we are able to measure the risk level of a driver or a trip, and then apply some alerts to avoid potential crash or accidents.\n",
    "\n",
    "### Industry Research\n",
    "\n",
    "I first did some industry research and learnt from this paper, [What can we learn from telematics car driving data: A survey](https://www.sciencedirect.com/science/article/pii/S0167668722000233#fg0010), that accelerometer signals and car speed data can surface some patterns in driving behavors. The authors used a simple CNN model to predict whether part of  driving signals is associated with a known driver. They achieved some good results in this prediction, so it tells CNN is able to learn behavior patterns from individuals.\n",
    "\n",
    "Sensor signals are temporal data. One of the most important characteristics in temporal data is every data point is a state and the next state can depend on previous states. It means the behavior a driver had at time step 10 is somehow a consequence of the behavior he/she did at time step 1. Just like a hard brake at 19:05:02 leads to the car to stop 3 seconds after. \n",
    "\n",
    "### How to learn this time dependent information from the data?\n",
    "\n",
    "CNN is a good approach. In image classification, an image's RGB is segregated into 3 channels. Each pixel is connected as a sequence, and passed into CNN as training data. Accelerometer signals are similar to this. X, y, z are just red, green, and blue. The convolution layer and pool layer extract important underlying features from the sequence. After the training, CNN is able to extract the best features from the sequence in order to make a good prediction. This can be considered as a type of \"aggregation\" over time series. \n",
    "\n",
    "\n",
    "### Optimize the idea and build a baseline model\n",
    "\n",
    "Here in this notebook, I replicated the idea from the paper but with different feature engineering techniques. \n",
    "\n",
    "The data the authors used only has speed signal, accelerometer signals on cars' movement direction, and the delta of direction change.\n",
    "\n",
    "But we have speed, and all vertical (x), horizontal (y), and movement direction (z) accelerometer signals. \n",
    "\n",
    "I first created a dataset using 50 time steps as a window sample with these 4 signals as 4 channels. And I normalized these 4 features, trained a CNN, but ended up with a poor model. I think it was speed signal causing the poor performance. Because speed signals are high correlated with movement direction signals and speed is a discrete value which hides many subtle changes. \n",
    "\n",
    "Then I removed speed signal and trained a CNN with only accelerometer signals. The model performed a bit better, but it still not satisfying. The reason was just I used standard scaler to normalize these signals. They are actually already in a uniform unit. Signals are more or less noisy. Standard scaler based on mean and std will be impacted by outliers.\n",
    "\n",
    "Finally, it sets a baseline at **93.6% F1 score** for predicting whether part of driving history is from a certain driver / device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beada403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d4363",
   "metadata": {},
   "source": [
    "### Load aggregated accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6012e2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6660, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df = pd.read_csv('aggregated_acc_signals.csv')\n",
    "\n",
    "driving_df['timestamp'] = pd.to_datetime(driving_df['timestamp'])\n",
    "\n",
    "driving_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8761a7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>device_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speed</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:02</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.157700</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>-0.986395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:03</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>0.062974</td>\n",
       "      <td>-0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:04</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.119859</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>-0.996581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:05</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.117717</td>\n",
       "      <td>0.056936</td>\n",
       "      <td>-0.996154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:06</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.137219</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>-0.986586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  device_id  trip_id           timestamp  speed     acc_x  \\\n",
       "0          1          1        1 2018-01-24 19:48:02      2 -0.157700   \n",
       "1          2          1        1 2018-01-24 19:48:03      0 -0.164984   \n",
       "2          3          1        1 2018-01-24 19:48:04      0 -0.119859   \n",
       "3          4          1        1 2018-01-24 19:48:05      0 -0.117717   \n",
       "4          5          1        1 2018-01-24 19:48:06      2 -0.137219   \n",
       "\n",
       "      acc_y     acc_z  \n",
       "0  0.044103 -0.986395  \n",
       "1  0.062974 -0.994265  \n",
       "2  0.030532 -0.996581  \n",
       "3  0.056936 -0.996154  \n",
       "4  0.070642 -0.986586  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc43dea",
   "metadata": {},
   "source": [
    "### Driving history \n",
    "By looking at the driving days of each device, we can see some of the days are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5d00d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_the_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24, 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11, 21, 28, 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10, 12, 19, 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12, 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1, 3, 9, 13, 19, 20, 28, 29, 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          day_of_the_month\n",
       "device_id                                 \n",
       "1                                   24, 25\n",
       "3                           11, 21, 28, 31\n",
       "5                           10, 12, 19, 22\n",
       "6                                       31\n",
       "7                                   12, 18\n",
       "10         1, 3, 9, 13, 19, 20, 28, 29, 30\n",
       "11                                      31"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def device_driving_history(df):\n",
    "\n",
    "    df['day_of_the_month'] = df['timestamp'].dt.day.astype(str)\n",
    "\n",
    "    return df[['device_id', 'day_of_the_month']]\\\n",
    "        .drop_duplicates()\\\n",
    "        .groupby(['device_id'])\\\n",
    "        .agg({'day_of_the_month': lambda x: ', '.join(x.values)})\n",
    "\n",
    "device_driving_history(driving_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70563353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driving_df = driving_df[~driving_df['device_id'].isin([6, 7, 1])] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44570a1f",
   "metadata": {},
   "source": [
    "### Transform signals into window samples\n",
    "\n",
    "We can apply a rolling window to the time steps for each trip. A window is a period of timestamps, or a list of row index in code. This helps us to easily extract samples for each window from the full driving history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff48b2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>device_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speed</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:02</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.157700</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>-0.986395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:03</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>0.062974</td>\n",
       "      <td>-0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:04</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.119859</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>-0.996581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:05</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.117717</td>\n",
       "      <td>0.056936</td>\n",
       "      <td>-0.996154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:06</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.137219</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>-0.986586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  device_id  trip_id           timestamp  speed     acc_x  \\\n",
       "0          1          1        1 2018-01-24 19:48:02      2 -0.157700   \n",
       "1          2          1        1 2018-01-24 19:48:03      0 -0.164984   \n",
       "2          3          1        1 2018-01-24 19:48:04      0 -0.119859   \n",
       "3          4          1        1 2018-01-24 19:48:05      0 -0.117717   \n",
       "4          5          1        1 2018-01-24 19:48:06      2 -0.137219   \n",
       "\n",
       "      acc_y     acc_z  \n",
       "0  0.044103 -0.986395  \n",
       "1  0.062974 -0.994265  \n",
       "2  0.030532 -0.996581  \n",
       "3  0.056936 -0.996154  \n",
       "4  0.070642 -0.986586  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbffff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6659</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6660 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      device_id  trip_id  time_step\n",
       "0             1        1          1\n",
       "1             1        1          2\n",
       "2             1        1          3\n",
       "3             1        1          4\n",
       "4             1        1          5\n",
       "...         ...      ...        ...\n",
       "6655         11        9        563\n",
       "6656         11        9        564\n",
       "6657         11        9        565\n",
       "6658         11        9        566\n",
       "6659         11        9        567\n",
       "\n",
       "[6660 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df[['device_id', 'trip_id', 'time_step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "749b5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_view(arr, window, overlap):\n",
    "    \"\"\" Apply rolling windows into the given array with an overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    arr = np.asarray(arr)\n",
    "    window_step = window - overlap\n",
    "    new_shape = arr.shape[:-1] + ((arr.shape[-1] - overlap) // window_step, window)\n",
    "    new_strides = (arr.strides[:-1] + (window_step * arr.strides[-1],) + arr.strides[-1:])\n",
    "    \n",
    "    return as_strided(arr, shape=new_shape, strides=new_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d1a37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window_samples(df, window, overlap):\n",
    "    \"\"\" Save all the row index of the rolling windows.\n",
    "    \"\"\"\n",
    "    \n",
    "    window_index_list = list()\n",
    "    labels_list = list()\n",
    "    \n",
    "    for (device_id, trip_id), trip_df in df.groupby(['device_id', 'trip_id']):\n",
    "#         print(trip_df)\n",
    "        trip_length = trip_df.shape[0]\n",
    "        window_index = windowed_view(trip_df.index, window, overlap)\n",
    "        labels = np.full((window_index.shape[0], 1), device_id)\n",
    "        window_index_list.append(window_index)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return np.concatenate(window_index_list), np.concatenate(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "632705fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_samples, labels = create_window_samples(driving_df, window=50, overlap=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99d0de5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    2, ...,   47,   48,   49],\n",
       "       [  58,   59,   60, ...,  105,  106,  107],\n",
       "       [  83,   84,   85, ...,  130,  131,  132],\n",
       "       ...,\n",
       "       [6543, 6544, 6545, ..., 6590, 6591, 6592],\n",
       "       [6568, 6569, 6570, ..., 6615, 6616, 6617],\n",
       "       [6593, 6594, 6595, ..., 6640, 6641, 6642]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97ee5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signals_per_window(df, window_samples, labels):\n",
    "    \"\"\" Since the given window samples are a list of windows with row index. \n",
    "    We now need to use the index to extract signals from the driving history data.\n",
    "    \"\"\"\n",
    "    \n",
    "    signal_window_samples_list = list()\n",
    "    \n",
    "    for window, device_id in zip(window_samples, labels):\n",
    "        \n",
    "        # Standardize the speed and accelerometer signals\n",
    "#         transformed_signals = StandardScaler().fit_transform(df.loc[window][['acc_x', 'acc_y', 'acc_z']])\n",
    "        transformed_signals = df.loc[window][['acc_x', 'acc_y', 'acc_z']]\n",
    "        signal_window_samples_list.append(transformed_signals)\n",
    "    \n",
    "    return np.asarray(signal_window_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31e0ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_window_samples = extract_signals_per_window(driving_df, window_samples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ad8c009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((219, 50, 3), (219, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_window_samples.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca49c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    101\n",
       "5      45\n",
       "3      37\n",
       "11     21\n",
       "6       6\n",
       "7       5\n",
       "1       4\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels.reshape(-1), name='labels').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12e12f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (43, 1)\n",
      "Shape after one-hot encoding:  (43, 7)\n"
     ]
    }
   ],
   "source": [
    "X = signal_window_samples.copy()\n",
    "y = labels.copy()\n",
    "\n",
    "device_to_label = {category: i for i, category in enumerate(set(y.reshape(-1)))}\n",
    "label_to_device = {i: category for i, category in enumerate(set(y.reshape(-1)))}\n",
    "device_to_label\n",
    "\n",
    "for device_id, label in device_to_label.items():\n",
    "    y[y == device_id] = label\n",
    "\n",
    "# Since the window samples are small, we should stratify on the device ids.\n",
    "# This can make sure we have both training / test samples for each device id.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.8, \n",
    "                                                    stratify=y, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = len(device_to_label)\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a700d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv1D(filters=10, kernel_size=3, activation='tanh', input_shape=(50, 3)))\n",
    "model.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "model.add(Conv1D(filters=8, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='tanh'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975a3ce",
   "metadata": {},
   "source": [
    "### Print out CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e28730ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 48, 10)            100       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 10)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 14, 8)             248       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 8)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 2, 4)              100       \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 4)                0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 483\n",
      "Trainable params: 483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77df96",
   "metadata": {},
   "source": [
    "### CNN Training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7411d6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 22:49:51.459473: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 1.9182 - accuracy: 0.2791 - val_loss: 1.8396 - val_accuracy: 0.2898\n",
      "Epoch 2/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8051 - accuracy: 0.3953 - val_loss: 1.7189 - val_accuracy: 0.7159\n",
      "Epoch 3/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6482 - accuracy: 0.6744 - val_loss: 1.6068 - val_accuracy: 0.4602\n",
      "Epoch 4/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5929 - accuracy: 0.5581 - val_loss: 1.5003 - val_accuracy: 0.4602\n",
      "Epoch 5/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4656 - accuracy: 0.5814 - val_loss: 1.3878 - val_accuracy: 0.5170\n",
      "Epoch 6/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3818 - accuracy: 0.6047 - val_loss: 1.2937 - val_accuracy: 0.6193\n",
      "Epoch 7/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2851 - accuracy: 0.6279 - val_loss: 1.1964 - val_accuracy: 0.6307\n",
      "Epoch 8/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2180 - accuracy: 0.7209 - val_loss: 1.1090 - val_accuracy: 0.6307\n",
      "Epoch 9/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1246 - accuracy: 0.7907 - val_loss: 1.0430 - val_accuracy: 0.8352\n",
      "Epoch 10/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1611 - accuracy: 0.6512 - val_loss: 0.9881 - val_accuracy: 0.8352\n",
      "Epoch 11/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0938 - accuracy: 0.7209 - val_loss: 0.9408 - val_accuracy: 0.8352\n",
      "Epoch 12/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.7209 - val_loss: 0.9015 - val_accuracy: 0.8352\n",
      "Epoch 13/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9842 - accuracy: 0.7442 - val_loss: 0.8646 - val_accuracy: 0.9318\n",
      "Epoch 14/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0114 - accuracy: 0.7209 - val_loss: 0.8291 - val_accuracy: 0.9318\n",
      "Epoch 15/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9592 - accuracy: 0.7674 - val_loss: 0.7996 - val_accuracy: 0.9205\n",
      "Epoch 16/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8280 - accuracy: 0.8140 - val_loss: 0.7687 - val_accuracy: 0.9261\n",
      "Epoch 17/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8405 - accuracy: 0.8372 - val_loss: 0.7451 - val_accuracy: 0.8352\n",
      "Epoch 18/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8608 - accuracy: 0.7907 - val_loss: 0.7212 - val_accuracy: 0.9318\n",
      "Epoch 19/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.8140 - val_loss: 0.7007 - val_accuracy: 0.9318\n",
      "Epoch 20/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7265 - accuracy: 0.8372 - val_loss: 0.6759 - val_accuracy: 0.9318\n",
      "Epoch 21/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7460 - accuracy: 0.8605 - val_loss: 0.6587 - val_accuracy: 0.9318\n",
      "Epoch 22/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8293 - accuracy: 0.7907 - val_loss: 0.6418 - val_accuracy: 0.9318\n",
      "Epoch 23/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7549 - accuracy: 0.8140 - val_loss: 0.6253 - val_accuracy: 0.9318\n",
      "Epoch 24/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7648 - accuracy: 0.7442 - val_loss: 0.6112 - val_accuracy: 0.9318\n",
      "Epoch 25/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7250 - accuracy: 0.7907 - val_loss: 0.5972 - val_accuracy: 0.9318\n",
      "Epoch 26/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6347 - accuracy: 0.8605 - val_loss: 0.5869 - val_accuracy: 0.9318\n",
      "Epoch 27/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7669 - accuracy: 0.7442 - val_loss: 0.5728 - val_accuracy: 0.9318\n",
      "Epoch 28/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6927 - accuracy: 0.8372 - val_loss: 0.5626 - val_accuracy: 0.9318\n",
      "Epoch 29/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.9070 - val_loss: 0.5547 - val_accuracy: 0.9318\n",
      "Epoch 30/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.8372 - val_loss: 0.5352 - val_accuracy: 0.9318\n",
      "Epoch 31/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.8605 - val_loss: 0.5245 - val_accuracy: 0.9318\n",
      "Epoch 32/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.8837 - val_loss: 0.5143 - val_accuracy: 0.9318\n",
      "Epoch 33/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6898 - accuracy: 0.7907 - val_loss: 0.5071 - val_accuracy: 0.9318\n",
      "Epoch 34/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7110 - accuracy: 0.7907 - val_loss: 0.4988 - val_accuracy: 0.9318\n",
      "Epoch 35/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.8605 - val_loss: 0.4935 - val_accuracy: 0.9318\n",
      "Epoch 36/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7235 - accuracy: 0.7907 - val_loss: 0.4868 - val_accuracy: 0.9318\n",
      "Epoch 37/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.8605 - val_loss: 0.4806 - val_accuracy: 0.9318\n",
      "Epoch 38/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.8140 - val_loss: 0.4729 - val_accuracy: 0.9318\n",
      "Epoch 39/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.8837 - val_loss: 0.4658 - val_accuracy: 0.9318\n",
      "Epoch 40/40\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7316 - accuracy: 0.7907 - val_loss: 0.4592 - val_accuracy: 0.9318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x292d8c8e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(X_train, Y_train, batch_size=1, epochs=40, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b06d4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e03a9",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "Calculate recall and precision for each device id.\n",
    "\n",
    "In the confusion matrix, we can see precision and recall for device 1, 6 and 7 are both 0. **It means the model didn't learn from these device samples.**\n",
    "\n",
    "However, for **device 3, 5, 10 and 11**, they have enough data for the model to learn some subtle patterns. **The overall F1 score for them is 93.6%, which is relative good.** This sets a baseline for the further fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba432f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_m = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "fig = plt.figure()\n",
    "labels = sorted(list(set(y.reshape(-1))))\n",
    "device_ids = [label_to_device[l] for l in labels]\n",
    "sns.heatmap(c_m, xticklabels=device_ids, yticklabels=device_ids, annot=True, \n",
    "            linewidths = 0.1, fmt=\"d\", cmap = \"YlGnBu\")\n",
    "plt.title(\"Confusion matrix\", fontsize = 15)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "confusion_matrix_plot = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9871a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/kg65sk251rz1g4h8_694mm9r0000gn/T/ipykernel_51488/3549722063.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = np.diag(c_m) / np.sum(c_m, axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           recall  precision        f1\n",
       "device_id                             \n",
       "1             0.0        NaN       NaN\n",
       "3             1.0   0.909091  0.952381\n",
       "5             1.0   1.000000  1.000000\n",
       "6             0.0        NaN       NaN\n",
       "7             0.0        NaN       NaN\n",
       "10            1.0   1.000000  1.000000\n",
       "11            1.0   0.653846  0.790698"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(c_m) / np.sum(c_m, axis = 1)\n",
    "precision = np.diag(c_m) / np.sum(c_m, axis = 0)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "evaluation_df = pd.DataFrame({\n",
    "    'device_id': device_ids,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1': f1\n",
    "}).set_index('device_id')\n",
    "\n",
    "evaluation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6acec6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall f1 score: 93.577%\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall f1 score: {:,.3f}%\".format(evaluation_df['f1'].mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e50153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
