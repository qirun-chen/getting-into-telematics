{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c77821",
   "metadata": {},
   "source": [
    "# Driver behavior mining\n",
    "\n",
    "Driver behavior mining can be an interesting topic in telemetics area. If we can learn the subtle patterns from risky drivers, we are able to measure the risk level of a driver or a trip, and then apply some alerts to avoid potential crash or accidents.\n",
    "\n",
    "### Industry Research\n",
    "\n",
    "I first did some industry research and learnt from this paper, [What can we learn from telematics car driving data: A survey](https://www.sciencedirect.com/science/article/pii/S0167668722000233#fg0010), that accelerometer signals and car speed data can surface some patterns in driving behavors. The authors used a simple CNN model to predict whether part of  driving signals is associated with a known driver. They achieved some good results in this prediction, so it tells CNN is able to learn behavior patterns from individuals.\n",
    "\n",
    "Sensor signals are temporal data. One of the most important characteristics in temporal data is every data point is a state and the next state can depend on previous states. It means the behavior a driver had at time step 10 is somehow a consequence of the behavior he/she did at time step 1. Just like a hard brake at 19:05:02 leads to the car to stop 3 seconds after. \n",
    "\n",
    "### How to learn this time dependent information from the data?\n",
    "\n",
    "CNN is a good approach. In image classification, an image's RGB is segregated into 3 channels. Each pixel is connected as a sequence, and passed into CNN as training data. Accelerometer signals are similar to this. X, y, z are just red, green, and blue. The convolution layer and pool layer extract important underlying features from the sequence. After the training, CNN is able to extract the best features from the sequence in order to make a good prediction. This can be considered as a type of \"aggregation\" over time series. \n",
    "\n",
    "\n",
    "### Optimize the idea and build a baseline model\n",
    "\n",
    "Here in this notebook, I replicated the idea from the paper but with different feature engineering techniques. \n",
    "\n",
    "The data the authors used only has speed signal, accelerometer signals on cars' movement direction, and the delta of direction change.\n",
    "\n",
    "But we have speed, and all vertical (x), horizontal (y), and movement direction (z) accelerometer signals. \n",
    "\n",
    "I first created a dataset using 50 time steps as a window sample with these 4 signals as 4 channels. And I normalized these 4 features, trained a CNN, but ended up with a poor model. I think it was speed signal causing the poor performance. Because speed signals are high correlated with movement direction signals and speed is a discrete value which hides many subtle changes. \n",
    "\n",
    "Then I removed speed signal and trained a CNN with only accelerometer signals. The model performed a bit better, but it still not satisfying. The reason was just I used standard scaler to normalize these signals. They are actually already in a uniform unit. Signals are more or less noisy. Standard scaler based on mean and std will be impacted by outliers.\n",
    "\n",
    "Finally, it sets a baseline at **67.3% F1 score** for predicting whether part of driving history is from a certain driver / device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beada403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d4363",
   "metadata": {},
   "source": [
    "### Load aggregated accelerometer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6012e2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6660, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df = pd.read_csv('aggregated_acc_signals.csv')\n",
    "\n",
    "driving_df['timestamp'] = pd.to_datetime(driving_df['timestamp'])\n",
    "\n",
    "driving_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8761a7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>device_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speed</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:02</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.157700</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>-0.986395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:03</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>0.062974</td>\n",
       "      <td>-0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:04</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.119859</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>-0.996581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:05</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.117717</td>\n",
       "      <td>0.056936</td>\n",
       "      <td>-0.996154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:06</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.137219</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>-0.986586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  device_id  trip_id           timestamp  speed     acc_x  \\\n",
       "0          1          1        1 2018-01-24 19:48:02      2 -0.157700   \n",
       "1          2          1        1 2018-01-24 19:48:03      0 -0.164984   \n",
       "2          3          1        1 2018-01-24 19:48:04      0 -0.119859   \n",
       "3          4          1        1 2018-01-24 19:48:05      0 -0.117717   \n",
       "4          5          1        1 2018-01-24 19:48:06      2 -0.137219   \n",
       "\n",
       "      acc_y     acc_z  \n",
       "0  0.044103 -0.986395  \n",
       "1  0.062974 -0.994265  \n",
       "2  0.030532 -0.996581  \n",
       "3  0.056936 -0.996154  \n",
       "4  0.070642 -0.986586  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc43dea",
   "metadata": {},
   "source": [
    "### Driving history \n",
    "By looking at the driving days of each device, we can see some of the days are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d00d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_the_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24, 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11, 21, 28, 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10, 12, 19, 22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12, 18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1, 3, 9, 13, 19, 20, 28, 29, 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          day_of_the_month\n",
       "device_id                                 \n",
       "1                                   24, 25\n",
       "3                           11, 21, 28, 31\n",
       "5                           10, 12, 19, 22\n",
       "6                                       31\n",
       "7                                   12, 18\n",
       "10         1, 3, 9, 13, 19, 20, 28, 29, 30\n",
       "11                                      31"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def device_driving_history(df):\n",
    "\n",
    "    df['day_of_the_month'] = df['timestamp'].dt.day.astype(str)\n",
    "\n",
    "    return df[['device_id', 'day_of_the_month']]\\\n",
    "        .drop_duplicates()\\\n",
    "        .groupby(['device_id'])\\\n",
    "        .agg({'day_of_the_month': lambda x: ', '.join(x.values)})\n",
    "\n",
    "device_driving_history(driving_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70563353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driving_df = driving_df[~driving_df['device_id'].isin([6, 7, 1])] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44570a1f",
   "metadata": {},
   "source": [
    "### Transform signals into window samples\n",
    "\n",
    "We can apply a rolling window to the time steps for each trip. A window is a period of timestamps, or a list of row index in code. This helps us to easily extract samples for each window from the full driving history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff48b2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_step</th>\n",
       "      <th>device_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>speed</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:02</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.157700</td>\n",
       "      <td>0.044103</td>\n",
       "      <td>-0.986395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:03</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.164984</td>\n",
       "      <td>0.062974</td>\n",
       "      <td>-0.994265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:04</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.119859</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>-0.996581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:05</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.117717</td>\n",
       "      <td>0.056936</td>\n",
       "      <td>-0.996154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-24 19:48:06</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.137219</td>\n",
       "      <td>0.070642</td>\n",
       "      <td>-0.986586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_step  device_id  trip_id           timestamp  speed     acc_x  \\\n",
       "0          1          1        1 2018-01-24 19:48:02      2 -0.157700   \n",
       "1          2          1        1 2018-01-24 19:48:03      0 -0.164984   \n",
       "2          3          1        1 2018-01-24 19:48:04      0 -0.119859   \n",
       "3          4          1        1 2018-01-24 19:48:05      0 -0.117717   \n",
       "4          5          1        1 2018-01-24 19:48:06      2 -0.137219   \n",
       "\n",
       "      acc_y     acc_z  \n",
       "0  0.044103 -0.986395  \n",
       "1  0.062974 -0.994265  \n",
       "2  0.030532 -0.996581  \n",
       "3  0.056936 -0.996154  \n",
       "4  0.070642 -0.986586  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbffff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>time_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6658</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6659</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6660 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      device_id  trip_id  time_step\n",
       "0             1        1          1\n",
       "1             1        1          2\n",
       "2             1        1          3\n",
       "3             1        1          4\n",
       "4             1        1          5\n",
       "...         ...      ...        ...\n",
       "6655         11        9        563\n",
       "6656         11        9        564\n",
       "6657         11        9        565\n",
       "6658         11        9        566\n",
       "6659         11        9        567\n",
       "\n",
       "[6660 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_df[['device_id', 'trip_id', 'time_step']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749b5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_view(arr, window, overlap):\n",
    "    \"\"\" Apply rolling windows into the given array with an overlap\n",
    "    \"\"\"\n",
    "    \n",
    "    arr = np.asarray(arr)\n",
    "    window_step = window - overlap\n",
    "    new_shape = arr.shape[:-1] + ((arr.shape[-1] - overlap) // window_step, window)\n",
    "    new_strides = (arr.strides[:-1] + (window_step * arr.strides[-1],) + arr.strides[-1:])\n",
    "    \n",
    "    return as_strided(arr, shape=new_shape, strides=new_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1a37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window_samples(df, window, overlap):\n",
    "    \"\"\" Save all the row index of the rolling windows.\n",
    "    \"\"\"\n",
    "    \n",
    "    window_index_list = list()\n",
    "    labels_list = list()\n",
    "    \n",
    "    for (device_id, trip_id), trip_df in df.groupby(['device_id', 'trip_id']):\n",
    "#         print(trip_df)\n",
    "        trip_length = trip_df.shape[0]\n",
    "        window_index = windowed_view(trip_df.index, window, overlap)\n",
    "        labels = np.full((window_index.shape[0], 1), device_id)\n",
    "        window_index_list.append(window_index)\n",
    "        labels_list.append(labels)\n",
    "\n",
    "    return np.concatenate(window_index_list), np.concatenate(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "632705fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_samples, labels = create_window_samples(driving_df, window=50, overlap=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d0de5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    1,    2, ...,   47,   48,   49],\n",
       "       [  58,   59,   60, ...,  105,  106,  107],\n",
       "       [  83,   84,   85, ...,  130,  131,  132],\n",
       "       ...,\n",
       "       [6543, 6544, 6545, ..., 6590, 6591, 6592],\n",
       "       [6568, 6569, 6570, ..., 6615, 6616, 6617],\n",
       "       [6593, 6594, 6595, ..., 6640, 6641, 6642]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97ee5074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_signals_per_window(df, window_samples, labels):\n",
    "    \"\"\" Since the given window samples are a list of windows with row index. \n",
    "    We now need to use the index to extract signals from the driving history data.\n",
    "    \"\"\"\n",
    "    \n",
    "    signal_window_samples_list = list()\n",
    "    \n",
    "    for window, device_id in zip(window_samples, labels):\n",
    "        \n",
    "        # Standardize the speed and accelerometer signals\n",
    "#         transformed_signals = StandardScaler().fit_transform(df.loc[window][['acc_x', 'acc_y', 'acc_z']])\n",
    "        transformed_signals = df.loc[window][['acc_x', 'acc_y', 'acc_z']]\n",
    "        signal_window_samples_list.append(transformed_signals)\n",
    "    \n",
    "    return np.asarray(signal_window_samples_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e0ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_window_samples = extract_signals_per_window(driving_df, window_samples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad8c009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((219, 50, 3), (219, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_window_samples.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca49c07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    101\n",
       "5      45\n",
       "3      37\n",
       "11     21\n",
       "6       6\n",
       "7       5\n",
       "1       4\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(labels.reshape(-1), name='labels').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e12f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (43, 1)\n",
      "Shape after one-hot encoding:  (43, 7)\n"
     ]
    }
   ],
   "source": [
    "X = signal_window_samples.copy()\n",
    "y = labels.copy()\n",
    "\n",
    "device_to_label = {category: i for i, category in enumerate(set(y.reshape(-1)))}\n",
    "label_to_device = {i: category for i, category in enumerate(set(y.reshape(-1)))}\n",
    "device_to_label\n",
    "\n",
    "for device_id, label in device_to_label.items():\n",
    "    y[y == device_id] = label\n",
    "\n",
    "# Since the window samples are small, we should stratify on the device ids.\n",
    "# This can make sure we have both training / test samples for each device id.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.8, \n",
    "                                                    stratify=y, \n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = len(device_to_label)\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a700d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv1D(filters=8, kernel_size=3, activation='tanh', input_shape=(50, 3)))\n",
    "model.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "model.add(Conv1D(filters=6, kernel_size=3, activation='tanh'))\n",
    "model.add(MaxPool1D(pool_size=3))\n",
    "\n",
    "model.add(Conv1D(filters=4, kernel_size=3, activation='tanh'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e975a3ce",
   "metadata": {},
   "source": [
    "### Print out CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e28730ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 48, 8)             80        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 16, 8)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 14, 6)             150       \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 4, 6)             0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 2, 4)              76        \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 4)                0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 35        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 341\n",
      "Trainable params: 341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb77df96",
   "metadata": {},
   "source": [
    "### CNN Training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7411d6cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-13 00:09:08.130639: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 4ms/step - loss: 1.9519 - accuracy: 0.1628 - val_loss: 1.9177 - val_accuracy: 0.2670\n",
      "Epoch 2/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8817 - accuracy: 0.3256 - val_loss: 1.8162 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7955 - accuracy: 0.4884 - val_loss: 1.7291 - val_accuracy: 0.6989\n",
      "Epoch 4/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6770 - accuracy: 0.5116 - val_loss: 1.6307 - val_accuracy: 0.5568\n",
      "Epoch 5/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6520 - accuracy: 0.4419 - val_loss: 1.5424 - val_accuracy: 0.6648\n",
      "Epoch 6/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5733 - accuracy: 0.3953 - val_loss: 1.4623 - val_accuracy: 0.6648\n",
      "Epoch 7/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.5072 - accuracy: 0.4651 - val_loss: 1.3913 - val_accuracy: 0.5568\n",
      "Epoch 8/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3784 - accuracy: 0.6512 - val_loss: 1.3267 - val_accuracy: 0.6648\n",
      "Epoch 9/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3284 - accuracy: 0.5814 - val_loss: 1.2703 - val_accuracy: 0.6648\n",
      "Epoch 10/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3417 - accuracy: 0.6047 - val_loss: 1.2242 - val_accuracy: 0.6648\n",
      "Epoch 11/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3467 - accuracy: 0.5581 - val_loss: 1.1871 - val_accuracy: 0.6648\n",
      "Epoch 12/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.2370 - accuracy: 0.5814 - val_loss: 1.1528 - val_accuracy: 0.6648\n",
      "Epoch 13/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.1969 - accuracy: 0.6047 - val_loss: 1.1206 - val_accuracy: 0.6648\n",
      "Epoch 14/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2053 - accuracy: 0.6047 - val_loss: 1.0906 - val_accuracy: 0.6648\n",
      "Epoch 15/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.2278 - accuracy: 0.5814 - val_loss: 1.0629 - val_accuracy: 0.6648\n",
      "Epoch 16/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.1456 - accuracy: 0.6047 - val_loss: 1.0388 - val_accuracy: 0.6648\n",
      "Epoch 17/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0990 - accuracy: 0.6279 - val_loss: 1.0192 - val_accuracy: 0.6648\n",
      "Epoch 18/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9474 - accuracy: 0.7674 - val_loss: 0.9968 - val_accuracy: 0.6648\n",
      "Epoch 19/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.0883 - accuracy: 0.6279 - val_loss: 0.9775 - val_accuracy: 0.6648\n",
      "Epoch 20/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.0488 - accuracy: 0.6512 - val_loss: 0.9572 - val_accuracy: 0.6648\n",
      "Epoch 21/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9752 - accuracy: 0.6279 - val_loss: 0.9425 - val_accuracy: 0.6648\n",
      "Epoch 22/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.1012 - accuracy: 0.6977 - val_loss: 0.9240 - val_accuracy: 0.6648\n",
      "Epoch 23/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9727 - accuracy: 0.7209 - val_loss: 0.9063 - val_accuracy: 0.6648\n",
      "Epoch 24/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9564 - accuracy: 0.6512 - val_loss: 0.8901 - val_accuracy: 0.6648\n",
      "Epoch 25/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9902 - accuracy: 0.6512 - val_loss: 0.8664 - val_accuracy: 0.6648\n",
      "Epoch 26/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.6512 - val_loss: 0.8426 - val_accuracy: 0.6648\n",
      "Epoch 27/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.9513 - accuracy: 0.7209 - val_loss: 0.8201 - val_accuracy: 0.6648\n",
      "Epoch 28/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9817 - accuracy: 0.6279 - val_loss: 0.8067 - val_accuracy: 0.6648\n",
      "Epoch 29/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.8451 - accuracy: 0.7442 - val_loss: 0.7722 - val_accuracy: 0.7614\n",
      "Epoch 30/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8090 - accuracy: 0.7674 - val_loss: 0.7410 - val_accuracy: 0.7443\n",
      "Epoch 31/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7695 - accuracy: 0.7442 - val_loss: 0.7092 - val_accuracy: 0.7045\n",
      "Epoch 32/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8114 - accuracy: 0.7907 - val_loss: 0.6737 - val_accuracy: 0.8125\n",
      "Epoch 33/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8475 - accuracy: 0.7674 - val_loss: 0.6436 - val_accuracy: 0.9261\n",
      "Epoch 34/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.7625 - accuracy: 0.7907 - val_loss: 0.6160 - val_accuracy: 0.9148\n",
      "Epoch 35/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.8837 - val_loss: 0.5882 - val_accuracy: 0.9318\n",
      "Epoch 36/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.8063 - accuracy: 0.7674 - val_loss: 0.5606 - val_accuracy: 0.9318\n",
      "Epoch 37/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7398 - accuracy: 0.7442 - val_loss: 0.5397 - val_accuracy: 0.9318\n",
      "Epoch 38/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.8372 - val_loss: 0.5234 - val_accuracy: 0.9261\n",
      "Epoch 39/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.8372 - val_loss: 0.5054 - val_accuracy: 0.9261\n",
      "Epoch 40/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7484 - accuracy: 0.8372 - val_loss: 0.4865 - val_accuracy: 0.9318\n",
      "Epoch 41/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.8605 - val_loss: 0.4710 - val_accuracy: 0.9318\n",
      "Epoch 42/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.7674 - val_loss: 0.4580 - val_accuracy: 0.9318\n",
      "Epoch 43/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7084 - accuracy: 0.7442 - val_loss: 0.4448 - val_accuracy: 0.9318\n",
      "Epoch 44/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.9070 - val_loss: 0.4347 - val_accuracy: 0.9318\n",
      "Epoch 45/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7674 - val_loss: 0.4293 - val_accuracy: 0.9318\n",
      "Epoch 46/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.8837 - val_loss: 0.4159 - val_accuracy: 0.9318\n",
      "Epoch 47/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.9070 - val_loss: 0.4038 - val_accuracy: 0.9318\n",
      "Epoch 48/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5559 - accuracy: 0.8605 - val_loss: 0.3963 - val_accuracy: 0.9318\n",
      "Epoch 49/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6387 - accuracy: 0.8140 - val_loss: 0.3886 - val_accuracy: 0.9318\n",
      "Epoch 50/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.8372 - val_loss: 0.3842 - val_accuracy: 0.9318\n",
      "Epoch 51/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.8837 - val_loss: 0.3763 - val_accuracy: 0.9318\n",
      "Epoch 52/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.8605 - val_loss: 0.3693 - val_accuracy: 0.9318\n",
      "Epoch 53/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.8605 - val_loss: 0.3659 - val_accuracy: 0.9318\n",
      "Epoch 54/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.9070 - val_loss: 0.3577 - val_accuracy: 0.9318\n",
      "Epoch 55/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5011 - accuracy: 0.8837 - val_loss: 0.3522 - val_accuracy: 0.9318\n",
      "Epoch 56/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.8837 - val_loss: 0.3476 - val_accuracy: 0.9318\n",
      "Epoch 57/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8140 - val_loss: 0.3447 - val_accuracy: 0.9318\n",
      "Epoch 58/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5867 - accuracy: 0.7907 - val_loss: 0.3438 - val_accuracy: 0.9318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.8837 - val_loss: 0.3390 - val_accuracy: 0.9318\n",
      "Epoch 60/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8372 - val_loss: 0.3358 - val_accuracy: 0.9318\n",
      "Epoch 61/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4837 - accuracy: 0.8837 - val_loss: 0.3340 - val_accuracy: 0.9318\n",
      "Epoch 62/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.8837 - val_loss: 0.3290 - val_accuracy: 0.9318\n",
      "Epoch 63/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.8605 - val_loss: 0.3261 - val_accuracy: 0.9318\n",
      "Epoch 64/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4878 - accuracy: 0.8605 - val_loss: 0.3231 - val_accuracy: 0.9318\n",
      "Epoch 65/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.9070 - val_loss: 0.3212 - val_accuracy: 0.9318\n",
      "Epoch 66/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.9070 - val_loss: 0.3196 - val_accuracy: 0.9318\n",
      "Epoch 67/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.8372 - val_loss: 0.3163 - val_accuracy: 0.9318\n",
      "Epoch 68/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8837 - val_loss: 0.3128 - val_accuracy: 0.9318\n",
      "Epoch 69/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.8837 - val_loss: 0.3099 - val_accuracy: 0.9318\n",
      "Epoch 70/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.9070 - val_loss: 0.3064 - val_accuracy: 0.9318\n",
      "Epoch 71/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.8372 - val_loss: 0.3054 - val_accuracy: 0.9318\n",
      "Epoch 72/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.9070 - val_loss: 0.3030 - val_accuracy: 0.9318\n",
      "Epoch 73/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.8837 - val_loss: 0.2991 - val_accuracy: 0.9318\n",
      "Epoch 74/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4710 - accuracy: 0.8605 - val_loss: 0.2974 - val_accuracy: 0.9318\n",
      "Epoch 75/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8837 - val_loss: 0.2959 - val_accuracy: 0.9318\n",
      "Epoch 76/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4138 - accuracy: 0.8837 - val_loss: 0.2941 - val_accuracy: 0.9318\n",
      "Epoch 77/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3932 - accuracy: 0.9302 - val_loss: 0.2931 - val_accuracy: 0.9318\n",
      "Epoch 78/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8605 - val_loss: 0.2914 - val_accuracy: 0.9318\n",
      "Epoch 79/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8372 - val_loss: 0.2901 - val_accuracy: 0.9318\n",
      "Epoch 80/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.8837 - val_loss: 0.2912 - val_accuracy: 0.9318\n",
      "Epoch 81/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.8837 - val_loss: 0.2887 - val_accuracy: 0.9318\n",
      "Epoch 82/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.8372 - val_loss: 0.2862 - val_accuracy: 0.9318\n",
      "Epoch 83/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.8605 - val_loss: 0.2826 - val_accuracy: 0.9318\n",
      "Epoch 84/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8837 - val_loss: 0.2793 - val_accuracy: 0.9318\n",
      "Epoch 85/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5548 - accuracy: 0.7907 - val_loss: 0.2784 - val_accuracy: 0.9318\n",
      "Epoch 86/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.7674 - val_loss: 0.2781 - val_accuracy: 0.9318\n",
      "Epoch 87/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.5280 - accuracy: 0.8140 - val_loss: 0.2774 - val_accuracy: 0.9318\n",
      "Epoch 88/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8605 - val_loss: 0.2775 - val_accuracy: 0.9318\n",
      "Epoch 89/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.9070 - val_loss: 0.2762 - val_accuracy: 0.9318\n",
      "Epoch 90/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4379 - accuracy: 0.8837 - val_loss: 0.2738 - val_accuracy: 0.9318\n",
      "Epoch 91/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4083 - accuracy: 0.8837 - val_loss: 0.2699 - val_accuracy: 0.9318\n",
      "Epoch 92/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4044 - accuracy: 0.8837 - val_loss: 0.2695 - val_accuracy: 0.9318\n",
      "Epoch 93/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8837 - val_loss: 0.2664 - val_accuracy: 0.9318\n",
      "Epoch 94/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.8837 - val_loss: 0.2648 - val_accuracy: 0.9318\n",
      "Epoch 95/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.9070 - val_loss: 0.2636 - val_accuracy: 0.9318\n",
      "Epoch 96/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.8605 - val_loss: 0.2622 - val_accuracy: 0.9318\n",
      "Epoch 97/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.8605 - val_loss: 0.2606 - val_accuracy: 0.9318\n",
      "Epoch 98/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.8372 - val_loss: 0.2592 - val_accuracy: 0.9318\n",
      "Epoch 99/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8837 - val_loss: 0.2611 - val_accuracy: 0.9318\n",
      "Epoch 100/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3933 - accuracy: 0.9070 - val_loss: 0.2625 - val_accuracy: 0.9318\n",
      "Epoch 101/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8837 - val_loss: 0.2559 - val_accuracy: 0.9318\n",
      "Epoch 102/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8837 - val_loss: 0.2548 - val_accuracy: 0.9318\n",
      "Epoch 103/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3793 - accuracy: 0.8837 - val_loss: 0.2536 - val_accuracy: 0.9318\n",
      "Epoch 104/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.9302 - val_loss: 0.2551 - val_accuracy: 0.9318\n",
      "Epoch 105/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4036 - accuracy: 0.9070 - val_loss: 0.2546 - val_accuracy: 0.9318\n",
      "Epoch 106/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7907 - val_loss: 0.2539 - val_accuracy: 0.9318\n",
      "Epoch 107/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8837 - val_loss: 0.2501 - val_accuracy: 0.9318\n",
      "Epoch 108/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.9070 - val_loss: 0.2489 - val_accuracy: 0.9318\n",
      "Epoch 109/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8605 - val_loss: 0.2480 - val_accuracy: 0.9318\n",
      "Epoch 110/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4143 - accuracy: 0.8605 - val_loss: 0.2461 - val_accuracy: 0.9318\n",
      "Epoch 111/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8605 - val_loss: 0.2456 - val_accuracy: 0.9318\n",
      "Epoch 112/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8837 - val_loss: 0.2439 - val_accuracy: 0.9318\n",
      "Epoch 113/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.8372 - val_loss: 0.2440 - val_accuracy: 0.9318\n",
      "Epoch 114/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4170 - accuracy: 0.9070 - val_loss: 0.2432 - val_accuracy: 0.9318\n",
      "Epoch 115/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7907 - val_loss: 0.2424 - val_accuracy: 0.9318\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8605 - val_loss: 0.2412 - val_accuracy: 0.9318\n",
      "Epoch 117/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8605 - val_loss: 0.2410 - val_accuracy: 0.9318\n",
      "Epoch 118/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8605 - val_loss: 0.2392 - val_accuracy: 0.9318\n",
      "Epoch 119/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.9070 - val_loss: 0.2385 - val_accuracy: 0.9318\n",
      "Epoch 120/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8372 - val_loss: 0.2375 - val_accuracy: 0.9318\n",
      "Epoch 121/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.8372 - val_loss: 0.2379 - val_accuracy: 0.9318\n",
      "Epoch 122/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.8837 - val_loss: 0.2370 - val_accuracy: 0.9318\n",
      "Epoch 123/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8605 - val_loss: 0.2352 - val_accuracy: 0.9318\n",
      "Epoch 124/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8605 - val_loss: 0.2337 - val_accuracy: 0.9318\n",
      "Epoch 125/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.8837 - val_loss: 0.2327 - val_accuracy: 0.9318\n",
      "Epoch 126/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.8372 - val_loss: 0.2322 - val_accuracy: 0.9318\n",
      "Epoch 127/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.8372 - val_loss: 0.2372 - val_accuracy: 0.9318\n",
      "Epoch 128/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.9070 - val_loss: 0.2326 - val_accuracy: 0.9318\n",
      "Epoch 129/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8605 - val_loss: 0.2299 - val_accuracy: 0.9318\n",
      "Epoch 130/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3033 - accuracy: 0.9070 - val_loss: 0.2290 - val_accuracy: 0.9318\n",
      "Epoch 131/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8605 - val_loss: 0.2278 - val_accuracy: 0.9318\n",
      "Epoch 132/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3797 - accuracy: 0.9070 - val_loss: 0.2269 - val_accuracy: 0.9318\n",
      "Epoch 133/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4197 - accuracy: 0.8605 - val_loss: 0.2262 - val_accuracy: 0.9318\n",
      "Epoch 134/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4155 - accuracy: 0.8372 - val_loss: 0.2277 - val_accuracy: 0.9318\n",
      "Epoch 135/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8372 - val_loss: 0.2282 - val_accuracy: 0.9318\n",
      "Epoch 136/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4078 - accuracy: 0.7907 - val_loss: 0.2238 - val_accuracy: 0.9318\n",
      "Epoch 137/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8605 - val_loss: 0.2228 - val_accuracy: 0.9318\n",
      "Epoch 138/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.9070 - val_loss: 0.2222 - val_accuracy: 0.9318\n",
      "Epoch 139/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4069 - accuracy: 0.8140 - val_loss: 0.2216 - val_accuracy: 0.9318\n",
      "Epoch 140/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4306 - accuracy: 0.8837 - val_loss: 0.2214 - val_accuracy: 0.9318\n",
      "Epoch 141/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.9070 - val_loss: 0.2203 - val_accuracy: 0.9318\n",
      "Epoch 142/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.9070 - val_loss: 0.2200 - val_accuracy: 0.9318\n",
      "Epoch 143/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3787 - accuracy: 0.8605 - val_loss: 0.2190 - val_accuracy: 0.9318\n",
      "Epoch 144/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.8605 - val_loss: 0.2183 - val_accuracy: 0.9318\n",
      "Epoch 145/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.8372 - val_loss: 0.2186 - val_accuracy: 0.9318\n",
      "Epoch 146/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.9302 - val_loss: 0.2174 - val_accuracy: 0.9318\n",
      "Epoch 147/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.2801 - accuracy: 0.9070 - val_loss: 0.2175 - val_accuracy: 0.9318\n",
      "Epoch 148/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8605 - val_loss: 0.2161 - val_accuracy: 0.9318\n",
      "Epoch 149/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8837 - val_loss: 0.2158 - val_accuracy: 0.9318\n",
      "Epoch 150/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8372 - val_loss: 0.2152 - val_accuracy: 0.9318\n",
      "Epoch 151/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3787 - accuracy: 0.8837 - val_loss: 0.2162 - val_accuracy: 0.9318\n",
      "Epoch 152/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.8837 - val_loss: 0.2189 - val_accuracy: 0.9318\n",
      "Epoch 153/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4080 - accuracy: 0.8837 - val_loss: 0.2153 - val_accuracy: 0.9318\n",
      "Epoch 154/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.7907 - val_loss: 0.2148 - val_accuracy: 0.9318\n",
      "Epoch 155/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8837 - val_loss: 0.2139 - val_accuracy: 0.9318\n",
      "Epoch 156/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8372 - val_loss: 0.2130 - val_accuracy: 0.9318\n",
      "Epoch 157/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8605 - val_loss: 0.2123 - val_accuracy: 0.9318\n",
      "Epoch 158/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3441 - accuracy: 0.8837 - val_loss: 0.2129 - val_accuracy: 0.9318\n",
      "Epoch 159/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3991 - accuracy: 0.8605 - val_loss: 0.2114 - val_accuracy: 0.9318\n",
      "Epoch 160/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.9070 - val_loss: 0.2115 - val_accuracy: 0.9318\n",
      "Epoch 161/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8372 - val_loss: 0.2114 - val_accuracy: 0.9318\n",
      "Epoch 162/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.9070 - val_loss: 0.2141 - val_accuracy: 0.9318\n",
      "Epoch 163/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3942 - accuracy: 0.8605 - val_loss: 0.2111 - val_accuracy: 0.9318\n",
      "Epoch 164/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.8372 - val_loss: 0.2094 - val_accuracy: 0.9318\n",
      "Epoch 165/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8837 - val_loss: 0.2088 - val_accuracy: 0.9318\n",
      "Epoch 166/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8837 - val_loss: 0.2086 - val_accuracy: 0.9318\n",
      "Epoch 167/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8372 - val_loss: 0.2082 - val_accuracy: 0.9318\n",
      "Epoch 168/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.8605 - val_loss: 0.2080 - val_accuracy: 0.9318\n",
      "Epoch 169/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8605 - val_loss: 0.2071 - val_accuracy: 0.9318\n",
      "Epoch 170/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.9070 - val_loss: 0.2078 - val_accuracy: 0.9318\n",
      "Epoch 171/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.9302 - val_loss: 0.2062 - val_accuracy: 0.9318\n",
      "Epoch 172/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3592 - accuracy: 0.9070 - val_loss: 0.2053 - val_accuracy: 0.9318\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.9070 - val_loss: 0.2047 - val_accuracy: 0.9318\n",
      "Epoch 174/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4025 - accuracy: 0.8605 - val_loss: 0.2046 - val_accuracy: 0.9318\n",
      "Epoch 175/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3451 - accuracy: 0.9070 - val_loss: 0.2076 - val_accuracy: 0.9318\n",
      "Epoch 176/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.9070 - val_loss: 0.2037 - val_accuracy: 0.9318\n",
      "Epoch 177/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8837 - val_loss: 0.2036 - val_accuracy: 0.9318\n",
      "Epoch 178/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8837 - val_loss: 0.2031 - val_accuracy: 0.9318\n",
      "Epoch 179/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.8140 - val_loss: 0.2058 - val_accuracy: 0.9318\n",
      "Epoch 180/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8837 - val_loss: 0.2021 - val_accuracy: 0.9318\n",
      "Epoch 181/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8372 - val_loss: 0.2030 - val_accuracy: 0.9318\n",
      "Epoch 182/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8837 - val_loss: 0.2019 - val_accuracy: 0.9318\n",
      "Epoch 183/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8837 - val_loss: 0.2016 - val_accuracy: 0.9318\n",
      "Epoch 184/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8837 - val_loss: 0.2005 - val_accuracy: 0.9318\n",
      "Epoch 185/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.4104 - accuracy: 0.8605 - val_loss: 0.1998 - val_accuracy: 0.9318\n",
      "Epoch 186/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3607 - accuracy: 0.8605 - val_loss: 0.1994 - val_accuracy: 0.9318\n",
      "Epoch 187/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8837 - val_loss: 0.1987 - val_accuracy: 0.9318\n",
      "Epoch 188/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8140 - val_loss: 0.1980 - val_accuracy: 0.9318\n",
      "Epoch 189/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8605 - val_loss: 0.1988 - val_accuracy: 0.9489\n",
      "Epoch 190/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4026 - accuracy: 0.8605 - val_loss: 0.1973 - val_accuracy: 0.9318\n",
      "Epoch 191/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8837 - val_loss: 0.1975 - val_accuracy: 0.9318\n",
      "Epoch 192/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.8605 - val_loss: 0.2001 - val_accuracy: 0.9318\n",
      "Epoch 193/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8837 - val_loss: 0.1971 - val_accuracy: 0.9318\n",
      "Epoch 194/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.9302 - val_loss: 0.1964 - val_accuracy: 0.9318\n",
      "Epoch 195/200\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.9070 - val_loss: 0.1954 - val_accuracy: 0.9318\n",
      "Epoch 196/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8837 - val_loss: 0.1944 - val_accuracy: 0.9489\n",
      "Epoch 197/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.8372 - val_loss: 0.1942 - val_accuracy: 0.9545\n",
      "Epoch 198/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3943 - accuracy: 0.8140 - val_loss: 0.1938 - val_accuracy: 0.9545\n",
      "Epoch 199/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8837 - val_loss: 0.1934 - val_accuracy: 0.9545\n",
      "Epoch 200/200\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3061 - accuracy: 0.9302 - val_loss: 0.1930 - val_accuracy: 0.9545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x297584670>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.fit(X_train, Y_train, batch_size=1, epochs=200, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b06d4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e03a9",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "Calculate recall and precision for each device id.\n",
    "\n",
    "In the confusion matrix, we can see precision and recall for device 1, 6 and 7 are both 0. **It means the model didn't learn from these device samples.**\n",
    "\n",
    "However, for **device 3, 5, 10 and 11**, they have enough data for the model to learn some subtle patterns. **The overall F1 score for them is 67.3%.** This sets a baseline for the further fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba432f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_m = confusion_matrix(Y_test.argmax(axis=1), Y_pred.argmax(axis=1))\n",
    "\n",
    "fig = plt.figure()\n",
    "labels = sorted(list(set(y.reshape(-1))))\n",
    "device_ids = [label_to_device[l] for l in labels]\n",
    "sns.heatmap(c_m, xticklabels=device_ids, yticklabels=device_ids, annot=True, \n",
    "            linewidths = 0.1, fmt=\"d\", cmap = \"YlGnBu\")\n",
    "plt.title(\"Confusion matrix\", fontsize = 15)\n",
    "plt.ylabel(\"True label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "confusion_matrix_plot = fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9871a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/kg65sk251rz1g4h8_694mm9r0000gn/T/ipykernel_52383/1451942175.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = np.diag(c_m) / np.sum(c_m, axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           recall  precision        f1\n",
       "device_id                             \n",
       "1             0.0   0.000000  0.000000\n",
       "3             1.0   0.909091  0.952381\n",
       "5             1.0   1.000000  1.000000\n",
       "6             0.8   1.000000  0.888889\n",
       "7             0.0   0.000000  0.000000\n",
       "10            1.0   1.000000  1.000000\n",
       "11            1.0   0.772727  0.871795"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = np.diag(c_m) / np.sum(c_m, axis = 1)\n",
    "precision = np.diag(c_m) / np.sum(c_m, axis = 0)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "evaluation_df = pd.DataFrame({\n",
    "    'device_id': device_ids,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1': f1\n",
    "}).set_index('device_id')\n",
    "\n",
    "evaluation_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6acec6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall f1 score: 67.329%\n"
     ]
    }
   ],
   "source": [
    "print(\"Overall f1 score: {:,.3f}%\".format(evaluation_df['f1'].fillna(0).mean()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
